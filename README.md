![jsr2](https://github.com/raj18verma/Face-and-Lip-Tracing-Prototype/blob/main/A%20cutting-edge%20%204ed17de6-dad6-443c-a10f-f9e5d6036a8f.png)

# Face and Lip Tracing Prototype Model using Python and Tensorflow
This repository contains the code and instructions to build a deep learning model capable of tracing facial movements and lip synchronization using Python and TensorFlow. The model processes video frames to perform lip reading, transcribing what a person is saying.

## Business Understanding
The objective of this feature is to develop a system that utilizes facial movement and lip synchronization tracing to verify the authenticity of interviewees. By employing machine learning techniques, particularly neural networks, we aim to mitigate interview fraud, especially in online settings. This system enhances hiring integrity and reinforces the security and trustworthiness of virtual interviews, thereby fostering a reliable recruitment environment.

## Explanation of Model Structure
Data Folder: Contains testing videos used to verify the functionality of the prototype.  
Lips Folder: Contains the virtual environment housing pre-trained model checkpoints.  
App Folder: Contains the main learning model built on deep neural networks, which requires training with datasets.

## Feature Engineering
Upon importing and installing dependencies, we utilize OpenCV to read and preprocess video data. Matplotlib is employed to visualize results, while imageio is used to create GIFs showcasing stacked frames. TensorFlow is utilized to construct a deep neural network for processing.

## Streamlit Application
To enhance accessibility and user-friendliness, we have developed a Streamlit application. This application efficiently processes user input, applies machine learning models, and displays transcriptions of what a person is saying.



##  Must Go Through the Live Working Demo of this Prototype:- https://drive.google.com/file/d/1izodtC4RrIQ9PTEommJPG1_TuzK-M8r4/view?usp=drive_link
 
